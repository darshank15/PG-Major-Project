{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/vatsal/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/vatsal/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import nltk\n",
    "from pprint import pprint\n",
    "from nltk.corpus import wordnet\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import PorterStemmer \n",
    "import gensim \n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import os\n",
    "import re\n",
    "from prettytable import PrettyTable\n",
    "import pandas as pd\n",
    "\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download('punkt')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entry(line): \n",
    "    w, c = line.split(\"\\t\", 2)\n",
    "    return (w, int(c))\n",
    "\n",
    "dict_path = \"./dict.txt\"\n",
    "dictionary = dict(entry(line) for line in open(dict_path))\n",
    "max_word_length = max(map(len, dictionary))\n",
    "total = float(sum(dictionary.values()))\n",
    "cleanup = re.compile(r'[^a-z0-9]')\n",
    "\n",
    "def word_prob(word): \n",
    "    return dictionary.get(word, 0) / total\n",
    "\n",
    "def segment(text): \n",
    "    text = re.sub(cleanup, ' ', text)\n",
    "    probs, lasts = [1.0], [0]\n",
    "    for i in range(1,len(text) + 1):\n",
    "        prob_k, k = max((probs[j] * word_prob(text[j:i]), j)for j in range(max(0, i - max_word_length), i))\n",
    "        probs.append(prob_k)\n",
    "        lasts.append(k)\n",
    "    words = []\n",
    "    i = len(text)\n",
    "    while i > 0:\n",
    "        words.append(text[lasts[i]:i])\n",
    "        i = lasts[i]\n",
    "    words.reverse()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob_corpora = []\n",
    "from glove import Corpus, Glove\n",
    "corpus = Corpus() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "top100 = {}\n",
    "top100['travel'] = ['#travel', '#wanderlust', '#nature', '#travelling', '#traveling', '#traveller', '#photography', '#traveler', '#trip', '#travels', '#vacation', '#love', '#travelers', '#adventure', '#tourist', '#landscape', '#travellers', '#explore', '#holiday', '#beautiful', '#tourism', '#hiking', '#beach', '#photo', '#sunset', '#photographer', '#mountains', '#globetrotter', '#summer', '#art', '#sky', '#treking', '#europe', '#view', '#architecture', '#sea', '#happy', '#fun', '#city', '#sun', '#lifestyle', '#amazing', '#wanderer', '#italy', '#follow', '#backpacking', '#life', '#visiting', '#fashion', '#autumn', '#explorer', '#ocean', '#outdoors', '#india', '#world', '#mountain', '#beauty', '#spain', '#backpacker', '#style', '#like', '#france', '#exploring', '#trekking', '#clouds', '#asia', '#me', '#friends', '#usa', '#canon', '#happiness', '#blogger', '#holidays', '#ig', '#sunrise', '#smile', '#germany', '#girl', '#island', '#wander', '#paradise', '#turkey', '#discover', '#italia', '#voyage', '#flowers', '#landscapes', '#sightseeing', '#outdoor', '#history', '#indonesia', '#cute', '#forest', '#paris', '#food', '#australia', '#bali', '#pic', '#beaches', '#inspiration']\n",
    "top100['food'] = ['#foodie', '#food', '#delicious', '#yummy', '#foodies', '#foods', '#eat', '#breakfast', '#dinner', '#tasty', '#cooking', '#lunch', '#homemade', '#dessert', '#love', '#eating', '#healthy', '#sweet', '#restaurant', '#photography', '#hungry', '#chef', '#blogger', '#travel', '#chocolate', '#baking', '#follow', '#cake', '#vegan', '#fresh', '#chicken', '#like', '#cook', '#amazing', '#blog', '#happy', '#favorite', '#brunch', '#coffee', '#weekend', '#fit', '#vegetarian', '#pasta', '#beautiful', '#pastry', '#fitness', '#gourmet', '#morning', '#desserts', '#seafood', '#eater', '#lifestyle', '#sweets', '#cafe', '#recipes', '#icecream', '#pizza', '#italy', '#culinary', '#candy', '#cheese', '#photographer', '#photo', '#cakes', '#recipe', '#noodles', '#diet', '#eats', '#rice', '#friends', '#cuisine', '#porridge', '#salad', '#nutrition', '#india', '#indonesia', '#bread', '#mornings', '#drinks', '#art', '#life', '#fun', '#gastronomy', '#sunday', '#cookies', '#kitchen', '#gym', '#me', '#beef', '#sushi', '#cupcakes', '#bake', '#spicy', '#saturday', '#fish', '#catering', '#burger', '#snack', '#music', '#delhi']\n",
    "top100['baby'] = ['#baby', '#kids', '#love', '#babies', '#cute', '#family', '#mom', '#fashion', '#newborn', '#children', '#happy', '#beautiful', '#photography', '#girl', '#babys', '#adorable', '#sweet', '#motherhood', '#pregnancy', '#handmade', '#funny', '#lovely', '#smile', '#mommy', '#life', '#daughter', '#style', '#follow', '#sweetheart', '#like', '#pregnant', '#beauty', '#precious', '#kid', '#child', '#fun', '#girls', '#mummy', '#tiny', '#twins', '#amazing', '#toddler', '#model', '#photo', '#mama', '#toys', '#boy', '#sleep', '#matching', '#autumn', '#enjoy', '#friends', '#pretty', '#art', '#parenting', '#live', '#mother', '#me', '#amor', '#photographer', '#princess', '#fairy', '#sale', '#happiness', '#boys', '#boutique', '#lifestyle', '#portrait', '#fall', '#son', '#pink', '#nature', '#childhood', '#cuteness', '#maternity', '#cool', '#travel', '#angel', '#best', '#halloween', '#play', '#weekend', '#october', '#dad', '#innocent', '#brand', '#makeup', '#home', '#parenthood', '#nice', '#little', '#sunday', '#flowers', '#mum', '#canon', '#infant', '#party', '#wedding', '#summer', '#hot']\n",
    "top100['jewellery'] = ['#jewellery', '#jewelry', '#fashion', '#accessories', '#earrings', '#necklace', '#style', '#jewels', '#handmade', '#beautiful', '#gemstone', '#trendy', '#gold', '#jewel', '#bracelet', '#rings', '#love', '#gems', '#silver', '#bracelets', '#design', '#ring', '#gemstones', '#crystals', '#shopping', '#stylish', '#art', '#pendant', '#diamond', '#cute', '#luxury', '#necklaces', '#bling', '#india', '#watches', '#handcrafted', '#designer', '#bijoux', '#trending', '#earring', '#bangles', '#bride', '#wedding', '#beauty', '#stone', '#tourmaline', '#charm', '#traditional', '#hyderabad', '#wholesaler', '#diamonds', '#bridal', '#photography', '#accessory', '#cabochons', '#tourmalines', '#stones', '#gem', '#goldplated', '#semiprecious', '#mumbai', '#silversmith', '#pendents', '#k', '#indian', '#sapphire', '#chennai', '#jewellers', '#girls', '#sale', '#jeweller', '#delhi', '#follow', '#fashionable', '#gift', '#bangalore', '#women', '#london', '#unique', '#ethnic', '#rawalpindi', '#crystal', '#vintage', '#oxidised', '#emerald', '#dubai', '#tucson', '#peridot', '#beads', '#makeup', '#saree', '#kunzite', '#chic', '#firecracker', '#pearl', '#lahore', '#choker', '#islamabad', '#wholesale', '#combo']\n",
    "# top100['selfie'] = ['#me', '#love', '#follow', '#smile', '#photography', '#style', '#beautiful', '#fashion', '#happy', '#cute', '#fun', '#girl', '#life', '#portrait', '#like', '#pretty', '#photo', '#handsome', '#travel', '#nature', '#eyes', '#face', '#hair', '#summer', '#art', '#friends', '#amazing', '#model', '#food', '#beauty', '#pic', '#daily', '#girls', '#lifestyle', '#look', '#makeup', '#swag', '#photographer', '#fitness', '#autumn', '#cool', '#family', '#sky', '#picture', '#likes', '#sun', '#mood', '#music', '#followers', '#outfit', '#boy', '#colorful', '#self', '#motivation', '#lovely', '#gay', '#pose', '#landscape', '#black', '#inspiration', '#happiness', '#halloween', '#artist', '#gym', '#liker', '#pink', '#portraits', '#blogger', '#fit', '#sunset', '#wanderlust', '#design', '#funny', '#italy', '#traveling', '#hot', '#awesome', '#holiday', '#following', '#photos', '#india', '#night', '#blue', '#weekend', '#view', '#october', '#party', '#trip', '#red', '#tattoo', '#man', '#looks', '#stylish', '#sea', '#nice', '#good', '#beard', '#beach', '#woman', '#aesthetic']\n",
    "top100['pets'] = ['#pet', '#pets', '#dog', '#cute', '#animals', '#love', '#dogs', '#cat', '#puppy', '#animal', '#cats', '#kitten', '#nature', '#kitty', '#meow', '#adorable', '#puppies', '#kittens', '#doggy', '#doggo', '#pup', '#photography', '#happy', '#funny', '#hound', '#eyes', '#beautiful', '#bunny', '#poodle', '#chihuahua', '#follow', '#rabbit', '#fluffy', '#paws', '#family', '#photo', '#lovely', '#chat', '#furry', '#daily', '#pomeranian', '#labrador', '#fun', '#autumn', '#sweet', '#maltese', '#smile', '#life', '#art', '#bunnies', '#hamster', '#baby', '#bird', '#me', '#world', '#bulldog', '#like', '#sleeping', '#tuesday', '#summer', '#parrots', '#husky', '#amor', '#rabbits', '#tot', '#zoo', '#doggie', '#meme', '#pug', '#istanbul', '#wildlife', '#beauty', '#adopt', '#girl', '#meowed', '#birds', '#purr', '#rescue', '#cavy', '#japan', '#doggies', '#halloween', '#photographer', '#woof', '#playtime', '#nice', '#portrait', '#relax', '#parakeet', '#singapore', '#parrot', '#fashion', '#fall', '#chihuahuas', '#friends', '#travel', '#morning', '#wolf', '#sweden', '#monday']\n",
    "top100['art'] = ['#art', '#artist', '#drawing', '#artwork', '#illustration', '#sketch', '#painting', '#draw', '#sketchbook', '#creative', '#design', '#love', '#photography', '#beautiful', '#pencil', '#ink', '#illustrator', '#drawings', '#portrait', '#arts', '#gallery', '#artistic', '#fashion', '#paint', '#doodle', '#nature', '#picture', '#watercolor', '#graphic', '#color', '#photo', '#sketching', '#music', '#style', '#pen', '#anime', '#cute', '#paintings', '#follow', '#paper', '#graphics', '#artists', '#like', '#travel', '#abstract', '#tattoo', '#cartoon', '#girl', '#masterpiece', '#sketches', '#beauty', '#inspiration', '#procreate', '#designer', '#comics', '#artworks', '#photographer', '#life', '#digital', '#illustrations', '#model', '#handmade', '#watercolour', '#draws', '#happy', '#painter', '#black', '#colorful', '#colors', '#comic', '#fun', '#landscape', '#exhibition', '#cool', '#colour', '#architecture', '#aesthetic', '#acrylic', '#smile', '#graffiti', '#arty', '#tattoos', '#amazing', '#lifestyle', '#sculpture', '#blue', '#rap', '#halloween', '#inked', '#funny', '#fantasy', '#character', '#me', '#summer', '#singer', '#studio', '#logo', '#collage', '#doodles', '#pictures']\n",
    "\n",
    "for topic in top100.keys():\n",
    "    top100[topic] = [r.replace('#', '') for r in top100[topic]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "top100_mapping = {}\n",
    "for key in top100.keys():\n",
    "    top100_stemmed = [ps.stem(word) for word in top100[key]]\n",
    "    top100_mapping[key]={}\n",
    "    for i in range(0,100):\n",
    "        top100_mapping[key][top100_stemmed[i]]=top100[key][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_punc(s):\n",
    "    new_str = \"\"\n",
    "    for c in s:\n",
    "        if c in punctuation:\n",
    "            new_str += \" \"\n",
    "        else:\n",
    "            new_str += c\n",
    "    return new_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['enjoy', 'littl', 'thing', 'life', 'someday', 'look', 'back', 'realiz', 'big', 'thing']\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing of input text\n",
    "\n",
    "input_sentence = \"Enjoy the little things in life Because someday you will look back and realize they were the BIG THINGS...\"\n",
    "# input_sentence = \"Straight out of The Sound of Music scenery is what you can wake up to, hiking and mountain biking your days away and enjoying Tyrolean hospitality.⁠\"\n",
    "# input_sentence = \"Magestic Mountains The views which i got during my roadtrip to Heaven of Earth Kasmir still give a pleasure to my soul @holidaycompass\"\n",
    "# input_sentence = \"Have you tried these homemade Brownies yet? 🤤🍫 This brownie is ultra rich, fudgy, and chewy just like the kind you buy at the store but oh so much better with no preservatives! 🙌🏻📷: @handletheheat Follow us @recipesofholly & for recipes check out my profile\"\n",
    "# input_sentence = \"#cutebabies #love_baby #kids #justbaby #angel #instagrambabies #ootd #pretty #instagramkids #bckcutie #cutekidsgotswag #myprettybabies #blackbabygoals #cutex10000 #beautifullymadebabies #bourgiebabies #gerberbaby #justbaby #mixedbabiesig #mixedracechildren #babylifezone #mixedkidzig #justbaby_world #newbornarrival #babypowergram #babiesarebeautiful #charmingkiddies #mixedbabiesworld #instadaily #cutebabies #instababy #babyboy #babies #mixedbabies #carters #babymodel #instafamous #igmodel\"\n",
    "# input_sentence = \"#tigger #tiggertheyorkie #yorkie #yorkies #yorkiesofinstagram #dog #dogs #dogsofinstagram #dogstagram #pets #pet #petsofinsta #petsofinstagram #igmodel #explorepage #explore #myplayplace #cuddleseason #november #fallseason #fall\"\n",
    "# input_sentence = \"#art #artist #drawing #jakeandamy #amysantiago #jakeperalta #sketch #draw #halloweenheist #traditionalart #sketchbook #sketching #creative #youngartist #artistsoninstagram #instaart #fanart #artsy #sketches #realistic #realism #realisticart #brooklynninenine #b99 #brooklyn99\"\n",
    "text = strip_punc(input_sentence.lower())\n",
    "toks = word_tokenize(text)\n",
    "toks_ = []\n",
    "for tok in toks:\n",
    "    tok = segment(tok)\n",
    "    for t in tok:\n",
    "        if wordnet.synsets(t):\n",
    "            t = ps.stem(t)\n",
    "            if t not in stop_words and len(t)>2:\n",
    "                toks_.append(t)\n",
    "\n",
    "input_words = toks_\n",
    "print(input_words)\n",
    "\n",
    "topic = \"travel\"\n",
    "# topic = \"food\"\n",
    "# topic = \"baby\"\n",
    "# topic = \"pets\"\n",
    "# topic = \"art\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['life', 'enjoy', 'never', 'give', 'big', 'thing', 'travel', 'travel', 'blogger', 'world', 'travel', 'good', 'relax', 'fit', 'model', 'beauti', 'view', 'india', 'natur', 'daili', 'fit', 'model', 'life', 'king', 'waterfal', 'bodi', 'transform', 'bodi', 'posit', 'cool', 'follow', 'follow']\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing of input seed hashtag\n",
    "\n",
    "input_sentence = \"#life #enjoy #nevergiveup #bigthings #travel #travelblogger #worldtraveler #instagood #relax #fitnessmodel #beautiful #view #india #nature #instadaily #fit #modellife #king #waterfall #bodytransformation #bodypositive #cool #followforfollowback #follow\"\n",
    "# input_sentence = \"#hiking #mountain #nature #beauty #adventure #travel #enjoy\"\n",
    "# input_sentence = \"#biking #mountain #heaven #roadtrip #trip #tour #travelislife #holiday #love\"\n",
    "# input_sentence = \"#foodporn #onthetable #eeeeeats #foodstyling #foodporn #igfood #healthyfood #food #foodie #foodphotography #foodpics #lovefood #healthybreakfast #fitfood #cleaneating #picoftheday #instagood #instayum #instarecipes #recipes #easyrecipes #foodies24hours #foodiepics #goodeating\"\n",
    "# input_sentence = \"#cutebabies #love_baby #kids #justbaby #angel #instagrambabies #ootd #pretty #instagramkids #bckcutie #cutekidsgotswag #myprettybabies #blackbabygoals #cutex10000 #beautifullymadebabies #bourgiebabies #gerberbaby #justbaby #mixedbabiesig #mixedracechildren #babylifezone #mixedkidzig #justbaby_world #newbornarrival #babypowergram #babiesarebeautiful #charmingkiddies #mixedbabiesworld #instadaily #cutebabies #instababy #babyboy #babies #mixedbabies #carters #babymodel #instafamous #igmodel\"\n",
    "# input_sentence = \"#tigger #tiggertheyorkie #yorkie #yorkies #yorkiesofinstagram #dog #dogs #dogsofinstagram #dogstagram #pets #pet #petsofinsta #petsofinstagram #igmodel #explorepage #explore #myplayplace #cuddleseason #november #fallseason #fall\"\n",
    "# input_sentence = \"#art #artist #drawing #jakeandamy #amysantiago #jakeperalta #sketch #draw #halloweenheist #traditionalart #sketchbook #sketching #creative #youngartist #artistsoninstagram #instaart #fanart #artsy #sketches #realistic #realism #realisticart #brooklynninenine #b99 #brooklyn99\"\n",
    "text = strip_punc(input_sentence.lower())\n",
    "toks = word_tokenize(text)\n",
    "origs = []\n",
    "for tok in toks:\n",
    "    tok = segment(tok)\n",
    "    for t in tok:\n",
    "        if wordnet.synsets(t):\n",
    "            t = ps.stem(t)\n",
    "            if t not in stop_words and len(t)>2:\n",
    "                origs.append(t)\n",
    "\n",
    "\n",
    "print(origs)\n",
    "# origs = set(origs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec.load(\"./models/word2vec.\"+topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4898\n"
     ]
    }
   ],
   "source": [
    "print(len(list(model.wv.vocab.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "(9, 300)\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "sent = []\n",
    "for word in input_words:\n",
    "    if word in model.wv.vocab:\n",
    "        sent.append(model.wv[word])\n",
    "    \n",
    "print(len(sent))\n",
    "sent = np.array(sent)\n",
    "print(sent.shape)\n",
    "embed = np.average(sent, axis = 0)\n",
    "print(embed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.5388641, 'like'), (0.47820386, 'fun'), (0.40900812, 'life'), (0.3878241, 'smile'), (0.38648802, 'friends'), (0.3528942, 'cute'), (0.3525224, 'love'), (0.31312725, 'holidays'), (0.29667693, 'view'), (0.28741422, 'happiness'), (0.28185275, 'sightseeing'), (0.26759738, 'amazing'), (0.2652718, 'summer'), (0.26058048, 'fashion'), (0.2226773, 'beaches'), (0.21887957, 'trip'), (0.21510084, 'vacation'), (0.21314585, 'adventure'), (0.2088632, 'flowers'), (0.20397404, 'follow')]\n"
     ]
    }
   ],
   "source": [
    "# Finding similarity of top 100 hashtags using word2vec\n",
    "\n",
    "ans = []\n",
    "for hasht in top100_mapping[topic]:\n",
    "    try:\n",
    "        v1 = model.wv[hasht]\n",
    "        simi = np.dot(v1, embed) / (np.linalg.norm(v1) * np.linalg.norm(embed))\n",
    "        ans.append((simi, top100_mapping[topic][hasht]))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "ans = sorted(ans, reverse = True)\n",
    "print(ans[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['like', 'fun', 'life', 'smile', 'friends', 'cute', 'love', 'holidays', 'view', 'happiness']\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "preds = [h[1] for h in ans[:k]]\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['like', 'fun', 'life', 'smile', 'friends', 'cute', 'love', 'holidays', 'view', 'happiness']\n",
      "['beauti', 'view', 'waterfal', 'travel', 'enjoy', 'transform', 'india', 'never', 'cool', 'daili', 'good', 'life', 'natur', 'give', 'thing', 'big', 'follow', 'world', 'blogger', 'bodi', 'fit', 'king', 'model', 'posit', 'relax']\n"
     ]
    }
   ],
   "source": [
    "print(preds)\n",
    "origs = set(origs)\n",
    "origs = list(origs)\n",
    "print(origs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# origs = ['life', 'enjoy', 'travel', 'relax', 'beauti', 'view', 'india', 'natur', 'fit', 'king', 'waterfal', 'cool', 'follow']\n",
    "# preds = ['memories', 'friends', 'happiness', 'smile', 'fun', 'love', 'life', 'cute', 'amazing', 'like']\n",
    "\n",
    "matr = np.empty((len(preds), len(origs)))\n",
    "\n",
    "for i, pred in enumerate(preds):\n",
    "    for j, orig in enumerate(origs):\n",
    "        try:\n",
    "            similarity = model.wv.similarity(ps.stem(orig), ps.stem(pred))\n",
    "        except:\n",
    "            similarity = 0\n",
    "        matr[i][j] = similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "like-------------follow\n",
      "fun-------------enjoy\n",
      "life-------------life\n",
      "smile-------------thing\n",
      "friends-------------thing\n",
      "cute-------------cool\n",
      "love-------------good\n",
      "holidays-------------good\n",
      "view-------------view\n",
      "happiness-------------daili\n",
      "+-----------+--------+------+----------+--------+-------+-----------+-------+-------+------+-------+------+------+-------+-------+-------+------+--------+-------+---------+-------+------+-------+-------+-------+-------+\n",
      "| Predicted | beauti | view | waterfal | travel | enjoy | transform | india | never | cool | daili | good | life | natur |  give | thing | big  | follow | world | blogger |  bodi | fit  |  king | model | posit | relax |\n",
      "+-----------+--------+------+----------+--------+-------+-----------+-------+-------+------+-------+------+------+-------+-------+-------+------+--------+-------+---------+-------+------+-------+-------+-------+-------+\n",
      "|    like   |  0.28  | 0.29 |   0.0    |  0.26  |  0.33 |    0.06   |  0.22 |  0.3  | 0.33 |  0.41 | 0.56 | 0.3  |  0.2  |  0.21 |  0.38 | 0.36 |  0.6   |  0.2  |   0.23  | -0.07 | 0.28 |  0.1  |  0.3  |  0.18 |  0.24 |\n",
      "|    fun    |  0.16  | 0.11 |   0.0    |  0.22  |  0.48 |    0.02   |  0.06 |  0.18 | 0.36 |  0.14 | 0.47 | 0.29 |  0.2  |  0.14 |  0.33 | 0.35 |  0.04  |  0.12 |   0.26  | -0.04 | 0.31 |  0.03 |  0.19 |  0.19 |  0.35 |\n",
      "|    life   |  0.27  | 0.25 |   0.0    |  0.59  |  0.27 |    0.05   |  0.27 |  0.27 | 0.07 |  0.43 | 0.4  | 1.0  |  0.31 |  -0.0 |  0.12 | 0.03 |  0.26  |  0.5  |   0.49  |  0.08 | 0.27 |  0.0  |  0.16 |  0.14 |  0.12 |\n",
      "|   smile   |  0.01  | 0.06 |   0.0    | -0.04  |  0.23 |    0.05   |  0.04 |  0.18 | 0.31 |  0.1  | 0.21 | 0.09 | -0.01 |  0.24 |  0.33 | 0.28 |  0.13  | -0.05 |   0.01  |  0.06 | 0.27 |  0.1  |  0.22 |  0.12 |  0.2  |\n",
      "|  friends  | -0.01  | 0.11 |   0.0    |  0.08  |  0.21 |   -0.01   |  0.11 |  0.26 | 0.16 |  0.13 | 0.28 | 0.16 | -0.04 |  0.28 |  0.36 | 0.2  |  0.32  |  0.04 |   0.17  | -0.07 | 0.19 |  0.28 |  0.18 | -0.05 |  0.1  |\n",
      "|    cute   |  0.05  | -0.0 |   0.0    |  -0.1  |  0.18 |    0.03   | -0.02 |  0.1  | 0.39 |  0.01 | 0.18 | 0.03 |  0.03 |  0.19 |  0.36 | 0.3  |  0.02  | -0.11 |   -0.0  |  0.04 | 0.35 |  0.05 |  0.25 |  0.18 |  0.16 |\n",
      "|    love   |  0.35  | 0.24 |   0.0    |  0.55  |  0.33 |   -0.08   |  0.24 |  0.24 | 0.2  |  0.4  | 0.55 | 0.54 |  0.36 |  -0.0 |  0.16 | 0.17 |  0.37  |  0.36 |   0.46  |  0.0  | 0.2  |  0.11 |  0.17 |  0.16 |  0.16 |\n",
      "|  holidays |  0.36  | 0.24 |   0.0    |  0.29  |  0.33 |   -0.02   |  0.1  |  0.1  | 0.18 |  0.19 | 0.38 | 0.24 |  0.18 |  0.07 |  0.12 | 0.29 |  0.2   |  0.24 |   0.15  | -0.01 | 0.15 |  0.11 |  0.13 |  0.04 |  0.35 |\n",
      "|    view   |  0.41  | 1.0  |   0.0    |  0.22  |  0.31 |    0.05   |  0.15 |  0.13 | 0.13 |  0.22 | 0.3  | 0.25 |  0.26 |  0.14 |  0.13 | 0.19 |  0.26  |  0.22 |   0.22  |  -0.1 | 0.08 |  0.14 |  0.12 |  0.1  |  0.18 |\n",
      "| happiness |  0.35  | 0.13 |   0.0    |  0.34  |  0.29 |   -0.04   |  0.0  | -0.04 | 0.12 |  0.35 | 0.27 | 0.3  |  0.25 | -0.07 |  0.14 | 0.04 |  0.2   |  0.13 |   0.29  |  0.15 | 0.25 | -0.07 |  0.07 |  0.31 |  0.25 |\n",
      "+-----------+--------+------+----------+--------+-------+-----------+-------+-------+------+-------+------+------+-------+-------+-------+------+--------+-------+---------+-------+------+-------+-------+-------+-------+\n",
      "0.9\n"
     ]
    }
   ],
   "source": [
    "# print(matr)\n",
    "accs = []\n",
    "tabl = PrettyTable()\n",
    "\n",
    "tabl.field_names = ['Predicted'] + origs\n",
    "for ind, row in enumerate(matr):\n",
    "    l = [preds[ind]] + [round(i,2) for i in row]\n",
    "    tabl.add_row(l)\n",
    "    accs.append(max(row))\n",
    "    indi = np.argmax(row)\n",
    "    print(preds[ind] + \"-------------\" + origs[indi])\n",
    "print(tabl)\n",
    "# print(accs)\n",
    "# print(np.mean(accs))\n",
    "\n",
    "ans = 0\n",
    "for acc in accs:\n",
    "    if round(acc,1) >= 0.4:\n",
    "        ans += 1\n",
    "print(ans / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "top100 = {}\n",
    "top100['travel'] = ['#travel', '#wanderlust', '#nature', '#travelling', '#traveling', '#traveller', '#photography', '#traveler', '#trip', '#travels', '#vacation', '#love', '#travelers', '#adventure', '#tourist', '#landscape', '#travellers', '#explore', '#holiday', '#beautiful', '#tourism', '#hiking', '#beach', '#photo', '#sunset', '#photographer', '#mountains', '#globetrotter', '#summer', '#art', '#sky', '#treking', '#europe', '#view', '#architecture', '#sea', '#happy', '#fun', '#city', '#sun', '#lifestyle', '#amazing', '#wanderer', '#italy', '#follow', '#backpacking', '#life', '#visiting', '#fashion', '#autumn', '#explorer', '#ocean', '#outdoors', '#india', '#world', '#mountain', '#beauty', '#spain', '#backpacker', '#style', '#like', '#france', '#exploring', '#trekking', '#clouds', '#asia', '#me', '#friends', '#usa', '#canon', '#happiness', '#blogger', '#holidays', '#ig', '#sunrise', '#smile', '#germany', '#girl', '#island', '#wander', '#paradise', '#turkey', '#discover', '#italia', '#voyage', '#flowers', '#landscapes', '#sightseeing', '#outdoor', '#history', '#indonesia', '#cute', '#forest', '#paris', '#food', '#australia', '#bali', '#pic', '#beaches', '#inspiration']\n",
    "top100['food'] = ['#foodie', '#food', '#delicious', '#yummy', '#foodies', '#foods', '#eat', '#breakfast', '#dinner', '#tasty', '#cooking', '#lunch', '#homemade', '#dessert', '#love', '#eating', '#healthy', '#sweet', '#restaurant', '#photography', '#hungry', '#chef', '#blogger', '#travel', '#chocolate', '#baking', '#follow', '#cake', '#vegan', '#fresh', '#chicken', '#like', '#cook', '#amazing', '#blog', '#happy', '#favorite', '#brunch', '#coffee', '#weekend', '#fit', '#vegetarian', '#pasta', '#beautiful', '#pastry', '#fitness', '#gourmet', '#morning', '#desserts', '#seafood', '#eater', '#lifestyle', '#sweets', '#cafe', '#recipes', '#icecream', '#pizza', '#italy', '#culinary', '#candy', '#cheese', '#photographer', '#photo', '#cakes', '#recipe', '#noodles', '#diet', '#eats', '#rice', '#friends', '#cuisine', '#porridge', '#salad', '#nutrition', '#india', '#indonesia', '#bread', '#mornings', '#drinks', '#art', '#life', '#fun', '#gastronomy', '#sunday', '#cookies', '#kitchen', '#gym', '#me', '#beef', '#sushi', '#cupcakes', '#bake', '#spicy', '#saturday', '#fish', '#catering', '#burger', '#snack', '#music', '#delhi']\n",
    "top100['baby'] = ['#baby', '#kids', '#love', '#babies', '#cute', '#family', '#mom', '#fashion', '#newborn', '#children', '#happy', '#beautiful', '#photography', '#girl', '#babys', '#adorable', '#sweet', '#motherhood', '#pregnancy', '#handmade', '#funny', '#lovely', '#smile', '#mommy', '#life', '#daughter', '#style', '#follow', '#sweetheart', '#like', '#pregnant', '#beauty', '#precious', '#kid', '#child', '#fun', '#girls', '#mummy', '#tiny', '#twins', '#amazing', '#toddler', '#model', '#photo', '#mama', '#toys', '#boy', '#sleep', '#matching', '#autumn', '#enjoy', '#friends', '#pretty', '#art', '#parenting', '#live', '#mother', '#me', '#amor', '#photographer', '#princess', '#fairy', '#sale', '#happiness', '#boys', '#boutique', '#lifestyle', '#portrait', '#fall', '#son', '#pink', '#nature', '#childhood', '#cuteness', '#maternity', '#cool', '#travel', '#angel', '#best', '#halloween', '#play', '#weekend', '#october', '#dad', '#innocent', '#brand', '#makeup', '#home', '#parenthood', '#nice', '#little', '#sunday', '#flowers', '#mum', '#canon', '#infant', '#party', '#wedding', '#summer', '#hot']\n",
    "top100['jewellery'] = ['#jewellery', '#jewelry', '#fashion', '#accessories', '#earrings', '#necklace', '#style', '#jewels', '#handmade', '#beautiful', '#gemstone', '#trendy', '#gold', '#jewel', '#bracelet', '#rings', '#love', '#gems', '#silver', '#bracelets', '#design', '#ring', '#gemstones', '#crystals', '#shopping', '#stylish', '#art', '#pendant', '#diamond', '#cute', '#luxury', '#necklaces', '#bling', '#india', '#watches', '#handcrafted', '#designer', '#bijoux', '#trending', '#earring', '#bangles', '#bride', '#wedding', '#beauty', '#stone', '#tourmaline', '#charm', '#traditional', '#hyderabad', '#wholesaler', '#diamonds', '#bridal', '#photography', '#accessory', '#cabochons', '#tourmalines', '#stones', '#gem', '#goldplated', '#semiprecious', '#mumbai', '#silversmith', '#pendents', '#k', '#indian', '#sapphire', '#chennai', '#jewellers', '#girls', '#sale', '#jeweller', '#delhi', '#follow', '#fashionable', '#gift', '#bangalore', '#women', '#london', '#unique', '#ethnic', '#rawalpindi', '#crystal', '#vintage', '#oxidised', '#emerald', '#dubai', '#tucson', '#peridot', '#beads', '#makeup', '#saree', '#kunzite', '#chic', '#firecracker', '#pearl', '#lahore', '#choker', '#islamabad', '#wholesale', '#combo']\n",
    "# top100['selfie'] = ['#me', '#love', '#follow', '#smile', '#photography', '#style', '#beautiful', '#fashion', '#happy', '#cute', '#fun', '#girl', '#life', '#portrait', '#like', '#pretty', '#photo', '#handsome', '#travel', '#nature', '#eyes', '#face', '#hair', '#summer', '#art', '#friends', '#amazing', '#model', '#food', '#beauty', '#pic', '#daily', '#girls', '#lifestyle', '#look', '#makeup', '#swag', '#photographer', '#fitness', '#autumn', '#cool', '#family', '#sky', '#picture', '#likes', '#sun', '#mood', '#music', '#followers', '#outfit', '#boy', '#colorful', '#self', '#motivation', '#lovely', '#gay', '#pose', '#landscape', '#black', '#inspiration', '#happiness', '#halloween', '#artist', '#gym', '#liker', '#pink', '#portraits', '#blogger', '#fit', '#sunset', '#wanderlust', '#design', '#funny', '#italy', '#traveling', '#hot', '#awesome', '#holiday', '#following', '#photos', '#india', '#night', '#blue', '#weekend', '#view', '#october', '#party', '#trip', '#red', '#tattoo', '#man', '#looks', '#stylish', '#sea', '#nice', '#good', '#beard', '#beach', '#woman', '#aesthetic']\n",
    "top100['pet'] = ['#pet', '#pets', '#dog', '#cute', '#animals', '#love', '#dogs', '#cat', '#puppy', '#animal', '#cats', '#kitten', '#nature', '#kitty', '#meow', '#adorable', '#puppies', '#kittens', '#doggy', '#doggo', '#pup', '#photography', '#happy', '#funny', '#hound', '#eyes', '#beautiful', '#bunny', '#poodle', '#chihuahua', '#follow', '#rabbit', '#fluffy', '#paws', '#family', '#photo', '#lovely', '#chat', '#furry', '#daily', '#pomeranian', '#labrador', '#fun', '#autumn', '#sweet', '#maltese', '#smile', '#life', '#art', '#bunnies', '#hamster', '#baby', '#bird', '#me', '#world', '#bulldog', '#like', '#sleeping', '#tuesday', '#summer', '#parrots', '#husky', '#amor', '#rabbits', '#tot', '#zoo', '#doggie', '#meme', '#pug', '#istanbul', '#wildlife', '#beauty', '#adopt', '#girl', '#meowed', '#birds', '#purr', '#rescue', '#cavy', '#japan', '#doggies', '#halloween', '#photographer', '#woof', '#playtime', '#nice', '#portrait', '#relax', '#parakeet', '#singapore', '#parrot', '#fashion', '#fall', '#chihuahuas', '#friends', '#travel', '#morning', '#wolf', '#sweden', '#monday']\n",
    "top100['art'] = ['#art', '#artist', '#drawing', '#artwork', '#illustration', '#sketch', '#painting', '#draw', '#sketchbook', '#creative', '#design', '#love', '#photography', '#beautiful', '#pencil', '#ink', '#illustrator', '#drawings', '#portrait', '#arts', '#gallery', '#artistic', '#fashion', '#paint', '#doodle', '#nature', '#picture', '#watercolor', '#graphic', '#color', '#photo', '#sketching', '#music', '#style', '#pen', '#anime', '#cute', '#paintings', '#follow', '#paper', '#graphics', '#artists', '#like', '#travel', '#abstract', '#tattoo', '#cartoon', '#girl', '#masterpiece', '#sketches', '#beauty', '#inspiration', '#procreate', '#designer', '#comics', '#artworks', '#photographer', '#life', '#digital', '#illustrations', '#model', '#handmade', '#watercolour', '#draws', '#happy', '#painter', '#black', '#colorful', '#colors', '#comic', '#fun', '#landscape', '#exhibition', '#cool', '#colour', '#architecture', '#aesthetic', '#acrylic', '#smile', '#graffiti', '#arty', '#tattoos', '#amazing', '#lifestyle', '#sculpture', '#blue', '#rap', '#halloween', '#inked', '#funny', '#fantasy', '#character', '#me', '#summer', '#singer', '#studio', '#logo', '#collage', '#doodles', '#pictures']\n",
    "top100['architecture'] = ['#architecture', '#design', '#art', '#photography', '#building', '#travel', '#architect', '#city', '#buildings', '#urban', '#beautiful', '#style', '#minimal', '#street', '#architectural', '#interior', '#skyscraper', '#perspective', '#abstract', '#lines', '#town', '#architectures', '#geometric', '#designer', '#composition', '#geometry', '#arts', '#cities', '#home', '#landscape', '#nature', '#photo', '#photographer', '#interiors', '#house', '#italy', '#love', '#cityscape', '#modern', '#decor', '#pattern', '#luxury', '#sky', '#construction', '#architects', '#inspiration', '#arch', '#traveling', '#minimalism', '#render', '#wanderlust', '#sketch', '#rendering', '#europe', '#lifestyle', '#history', '#autumn', '#view', '#decoration', '#light', '#trip', '#amazing', '#concrete', '#paris', '#sunset', '#facade', '#artist', '#modernism', '#contemporary', '#sun', '#london', '#travelling', '#furniture', '#ig', '#life', '#france', '#church', '#traveller', '#canon', '#pic', '#explore', '#picture', '#details', '#colors', '#traveler', '#vacation', '#tourism', '#italia', '#milano', '#clouds', '#engineering', '#fashion', '#germany', '#spain', '#villa', '#wood', '#3d', '#exterior', '#blue', '#artwork']\n",
    "top100['nature'] = ['#nature', '#photography', '#landscape', '#travel', '#beautiful', '#love', '#autumn', '#photo', '#sky', '#photographer', '#mountains', '#sunset', '#outdoors', '#clouds', '#art', '#flowers', '#beauty', '#tree', '#wanderlust', '#follow', '#amazing', '#adventure', '#trees', '#forest', '#view', '#explore', '#green', '#summer', '#life', '#sun', '#hiking', '#colors', '#wildlife', '#mountain', '#travelling', '#fashion', '#like', '#canon', '#trip', '#sea', '#ig', '#happy', '#water', '#natural', '#fall', '#outdoor', '#beach', '#style', '#traveling', '#fun', '#blue', '#landscapes', '#sunrise', '#flower', '#animals', '#lake', '#cute', '#picture', '#macro', '#me', '#river', '#earth', '#natures', '#friends', '#leaves', '#followers', '#vacation', '#plants', '#weather', '#smile', '#garden', '#india', '#girl', '#pic', '#november', '#photos', '#world', '#wild', '#birds', '#model', '#traveller', '#peace', '#lifestyle', '#bird', '#walk', '#animal', '#holiday', '#discover', '#trekking', '#portrait', '#morning', '#nice', '#sunday', '#ocean', '#sunsets', '#traveler', '#fitness', '#rain', '#italy', '#winter']\n",
    "\n",
    "for topic in top100.keys():\n",
    "    top100[topic] = [r.replace('#', '') for r in top100[topic]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "top100_mapping = {}\n",
    "for key in top100.keys():\n",
    "    top100_stemmed = [ps.stem(word) for word in top100[key]]\n",
    "    top100_mapping[key]={}\n",
    "    for i in range(0,100):\n",
    "        top100_mapping[key][top100_stemmed[i]]=top100[key][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob_corpora = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dic = {}\n",
    "for topic in top100.keys():\n",
    "    final_dic[topic] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "travel\n",
      "./jsons/travel/Luxarytravel.json\n",
      "./jsons/travel/travelbook.json\n",
      "./jsons/travel/Traveldeeper.json\n",
      "./jsons/travel/Hiking.json\n",
      "./jsons/travel/travelquotes.json\n",
      "./jsons/travel/travelstoke.json\n",
      "./jsons/travel/travel.json\n",
      "./jsons/travel/traveladdict.json\n",
      "./jsons/travel/travellersnotebook.json\n",
      "./jsons/travel/travelguide.json\n",
      "./jsons/travel/Travelabout.json\n",
      "./jsons/travel/trip.json\n",
      "./jsons/travel/solotravel.json\n",
      "./jsons/travel/Travelphotography.json\n",
      "./jsons/travel/travelbug.json\n",
      "./jsons/travel/travelpic.json\n",
      "./jsons/travel/travelgram.json\n",
      "./jsons/travel/tourist.json\n",
      "./jsons/travel/travelislife.json\n",
      "./jsons/travel/beachvibes.json\n",
      "./jsons/travel/treking.json\n",
      "./jsons/travel/Travelawesome.json\n",
      "./jsons/travel/traveltheglobe.json\n",
      "./jsons/travel/travelworld.json\n",
      "./jsons/travel/worldtraveller.json\n",
      "./jsons/travel/Travellove.json\n",
      "./jsons/travel/nature.json\n",
      "./jsons/travel/travelcaptures.json\n",
      "./jsons/travel/Citytravel.json\n",
      "food\n",
      "./jsons/food/foodphotography.json\n",
      "./jsons/food/foodporn.json\n",
      "./jsons/food/foodstyling.json\n",
      "./jsons/food/foodstagram.json\n",
      "./jsons/food/foodblog.json\n",
      "./jsons/food/foodaddict.json\n",
      "baby\n",
      "./jsons/baby/baby.json\n",
      "./jsons/baby/babyfashion.json\n",
      "./jsons/baby/babycute.json\n",
      "./jsons/baby/kids.json\n",
      "./jsons/baby/babylove.json\n",
      "./jsons/baby/babiesworld.json\n",
      "jewellery\n",
      "./jsons/jewellery/jewelerydesign.json\n",
      "./jsons/jewellery/imitationjewellery.json\n",
      "./jsons/jewellery/fashionjewelry.json\n",
      "./jsons/jewellery/jewellery.json\n",
      "pet\n",
      "./jsons/pet/petstagram.json\n",
      "./jsons/pet/instapet.json\n",
      "./jsons/pet/petlover.json\n",
      "./jsons/pet/petscorner.json\n",
      "./jsons/pet/petsofinstagram.json\n",
      "./jsons/pet/pet.json\n",
      "art\n",
      "./jsons/art/artist.json\n",
      "./jsons/art/artistsoninstagram.json\n",
      "./jsons/art/art.json\n",
      "./jsons/art/artoftheday.json\n",
      "./jsons/art/drawing.json\n",
      "./jsons/art/artwork.json\n",
      "architecture\n",
      "./jsons/architecture/modernarchitecture.json\n",
      "./jsons/architecture/architecture.json\n",
      "./jsons/architecture/architecturelovers.json\n",
      "./jsons/architecture/architecturephotography.json\n",
      "./jsons/architecture/architecture_hunter.json\n",
      "./jsons/architecture/architectureporn.json\n",
      "nature\n",
      "./jsons/nature/nature_good.json\n",
      "./jsons/nature/naturelovers.json\n",
      "./jsons/nature/natureshot.json\n",
      "./jsons/nature/nature.json\n",
      "./jsons/nature/naturephotography.json\n",
      "./jsons/nature/naturebeauty.json\n"
     ]
    }
   ],
   "source": [
    "for topic in top100.keys():\n",
    "    for r, d, f in os.walk(\"./jsons/\"+topic):\n",
    "        print(topic)\n",
    "        df = pd.read_csv('./csv/train/final_train_'+topic+\".csv\")\n",
    "        dic = dict()\n",
    "        for file in f:\n",
    "            path = r+\"/\"+file\n",
    "            print(path)\n",
    "            if '.json' in file:\n",
    "                file_ptr = open(path, \"r\")\n",
    "                tmp_dic = json.load(file_ptr)\n",
    "                dic.update(tmp_dic)\n",
    "        final_dic[topic] = dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = {}\n",
    "for topic in top100.keys():\n",
    "    model[topic] = gensim.models.Word2Vec.load(\"./models/word2vec.\"+topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hashtag(text):\n",
    "    hashtags = []\n",
    "    others = \"\"\n",
    "    texts = text.split(\" \")\n",
    "    for t in texts:\n",
    "        if t==\"\":\n",
    "            continue\n",
    "        if t[0]=='#':\n",
    "            hashtags.append(t)\n",
    "        else:\n",
    "            others = others + t + \" \"\n",
    "    return hashtags,others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fans=0\n",
    "c = 0\n",
    "x=0\n",
    "x1=0\n",
    "# df = pd.read_csv('./csv/test/final_test.csv')\n",
    "df = pd.read_csv('./csv/test/test-pred.csv')\n",
    "baseline = True\n",
    "for index,row in df.iterrows():\n",
    "    \n",
    "#     post_id = row['post_id'].split('.jpeg')[0]\n",
    "#     topic = row['topic']\n",
    "    post_id = row['filename'].split('.jpeg')[0]\n",
    "    topic = row['class1']\n",
    "    \n",
    "    try:\n",
    "        input_sentence = final_dic[topic][post_id]['text_des']\n",
    "    except:\n",
    "        x+=1\n",
    "        continue\n",
    "    \n",
    "    hashtags,others = extract_hashtag(input_sentence)\n",
    "    if(len(hashtags)<=3):\n",
    "        x1+=1\n",
    "        continue\n",
    "    others = others + hashtags[0]\n",
    "    others = others + \" \" + hashtags[1]\n",
    "    others = others + \" \" + hashtags[2]\n",
    "    del hashtags[0]\n",
    "    del hashtags[0]\n",
    "    del hashtags[0]\n",
    "    \n",
    "    text = strip_punc(others.lower())\n",
    "    toks = word_tokenize(text)\n",
    "    toks_ = []\n",
    "    for tok in toks:\n",
    "        tok = segment(tok)\n",
    "        for t in tok:\n",
    "            if wordnet.synsets(t):\n",
    "                t = ps.stem(t)\n",
    "                if t not in stop_words and len(t)>2:\n",
    "                    toks_.append(t)\n",
    "\n",
    "    input_words = toks_\n",
    "    \n",
    "    input_words = set(input_words)\n",
    "    input_words = list(input_words)\n",
    "    if(len(input_words)<=3):\n",
    "        continue\n",
    "    sent = []\n",
    "    for word in input_words:\n",
    "        if word in model[topic].wv.vocab:\n",
    "            sent.append(model[topic].wv[word])\n",
    "\n",
    "    sent = np.array(sent)\n",
    "    embed = np.average(sent, axis = 0)\n",
    "    \n",
    "    ans = []\n",
    "    for hasht in top100_mapping[topic]:\n",
    "        try:\n",
    "            v1 = model[topic].wv[hasht]\n",
    "            simi = np.dot(v1, embed) / (np.linalg.norm(v1) * np.linalg.norm(embed))\n",
    "            ans.append((simi, top100_mapping[topic][hasht]))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    ans = sorted(ans, reverse = True)\n",
    "#     print(ans)\n",
    "    k = 10\n",
    "    preds = [h[1] for h in ans[:k]]\n",
    "    \n",
    "    tt = \"\"\n",
    "    for h in hashtags:\n",
    "        tt = tt+h\n",
    "    text = strip_punc(tt.lower())\n",
    "    toks = word_tokenize(text)\n",
    "    toks_ = []\n",
    "    for tok in toks:\n",
    "        tok = segment(tok)\n",
    "        for t in tok:\n",
    "            if wordnet.synsets(t):\n",
    "                t = ps.stem(t)\n",
    "                if t not in stop_words and len(t)>2:\n",
    "                    toks_.append(t)\n",
    "    \n",
    "    toks_ = set(toks_)\n",
    "    toks_ = list(toks_)\n",
    "    matr = np.empty((len(preds), len(toks_)))\n",
    "\n",
    "    for i, pred in enumerate(preds):\n",
    "        for j, orig in enumerate(toks_):\n",
    "            try:\n",
    "                v1 = model[topic].wv[ps.stem(pred)]\n",
    "                v2 = model[topic].wv[ps.stem(orig)]\n",
    "                similarity = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "            except:\n",
    "                similarity = 0\n",
    "            matr[i][j] = similarity\n",
    "    \n",
    "    \n",
    "    accs = []\n",
    "    tabl = PrettyTable()\n",
    "    tabl.field_names = ['Predicted'] + toks_\n",
    "    for ind, row in enumerate(matr):\n",
    "        l = [preds[ind]] + [round(i,2) for i in row]\n",
    "        tabl.add_row(l)\n",
    "        try:\n",
    "            accs.append(max(row))\n",
    "        except:\n",
    "            accs.append(0)\n",
    "#         indi = np.argmax(row)\n",
    "\n",
    "    acc_ans = 0\n",
    "    for acc in accs:\n",
    "        if round(acc,1) >= 0.4:\n",
    "            acc_ans += 1\n",
    "\n",
    "    acc_ans=float(acc_ans)/float(len(preds))\n",
    "#     print(acc_ans)\n",
    "    fans=fans+acc_ans\n",
    "    c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "865\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "431\n"
     ]
    }
   ],
   "source": [
    "print(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1471\n"
     ]
    }
   ],
   "source": [
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.5465669612509\n"
     ]
    }
   ],
   "source": [
    "print((fans/c)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
